{
  "paperId": "20c711a665154b3caaa73524f5f1e39a58a12fbb",
  "externalIds": {
    "DBLP": "journals/jfr/LottesBCMS20",
    "MAG": "2967632598",
    "DOI": "10.1002/rob.21901",
    "CorpusId": 202095004
  },
  "url": "https://www.semanticscholar.org/paper/20c711a665154b3caaa73524f5f1e39a58a12fbb",
  "title": "Robust joint stem detection and crop‐weed classification using image sequences for plant‐specific treatment in precision farming",
  "venue": "J. Field Robotics",
  "year": 2019,
  "citationCount": 80,
  "influentialCitationCount": 1,
  "openAccessPdf": {
    "url": "https://onlinelibrary.wiley.com/doi/pdfdirect/10.1002/rob.21901",
    "status": "CLOSED",
    "license": null,
    "disclaimer": "Notice: The following paper fields have been elided by the publisher: {'references'}. Paper or abstract available at https://api.unpaywall.org/v2/10.1002/rob.21901?email=<INSERT_YOUR_EMAIL> or https://doi.org/10.1002/rob.21901, which is subject to the license by the author or copyright owner provided with this content. Please go to the source to verify the license and copyright information for your use."
  },
  "fieldsOfStudy": [
    "Computer Science"
  ],
  "publicationTypes": [
    "JournalArticle"
  ],
  "authors": [
    {
      "authorId": "3414541",
      "name": "Philipp Lottes"
    },
    {
      "authorId": "3350812",
      "name": "Jens Behley"
    },
    {
      "authorId": "25884999",
      "name": "Nived Chebrolu"
    },
    {
      "authorId": "26351048",
      "name": "Andres Milioto"
    },
    {
      "authorId": "1722062",
      "name": "C. Stachniss"
    }
  ],
  "abstract": "Conventional farming still relies on large quantities of agrochemicals for weed management which have several negative side‐effects on the environment. Autonomous robots offer the potential to reduce the amount of chemicals applied, as robots can monitor and treat each plant in the field individually and thereby circumventing the uniform chemical treatment of the whole field. Such agricultural robots need the ability to identify individual crops and weeds in the field using sensor data and must additionally select effective treatment methods based on the type of weed. For example, certain types of weeds can only be effectively treated mechanically due to their resistance to herbicides, whereas other types can be treated trough selective spraying. In this article, we present a novel system that provides the necessary information for effective plant‐specific treatment. It estimates the stem location for weeds, which enables the robots to perform precise mechanical treatment, and at the same time provides the pixel‐accurate area covered by weeds for treatment through selective spraying. The major challenge in developing such a system is the large variability in the visual appearance that occurs in different fields. Thus, an effective classification system has to robustly handle substantial environmental changes including varying weed pressure, various weed types, different growth stages, changing visual appearance of the plants and the soil. Our approach uses an end‐to‐end trainable fully convolutional network that simultaneously estimates plant stem positions as well as the spatial extent of crop plants and weeds. It jointly learns how to detect the stems and the pixel‐wise semantic segmentation and incorporates spatial information by considering image sequences of local field strips. The jointly learned feature representation for both tasks furthermore exploits the crop arrangement information that is often present in crop fields. This information is considered even if it is only observable from the image sequences and not a single image. Such image sequences, as typically provided by robots navigating over the field along crop rows, enable our approach to robustly estimate the semantic segmentation and stem positions despite the large variations encountered in different fields. We implemented and thoroughly tested our approach on images from multiple farms in different countries. The experiments show that our system generalizes well to previously unseen fields under varying environmental conditions—a key capability to deploy such systems in the real world. Compared to state‐of‐the‐art approaches, our approach generalizes well to unseen fields and not only substantially improves the stem detection accuracy, that is, distinguishing crop and weed stems, but also improves the semantic segmentation performance.",
  "references": null
}