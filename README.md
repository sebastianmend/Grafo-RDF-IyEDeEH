# Grafo de Conocimiento sobre Agricultura de PrecisiÃ³n

**Proyecto de Interoperabilidad y ExplotaciÃ³n de Datos en Ecosistemas HeterogÃ©neos (BIM1) - UTPL**

ConstrucciÃ³n de un grafo de conocimiento a partir de publicaciones cientÃ­ficas sobre Agricultura de PrecisiÃ³n, desde la extracciÃ³n de datos hasta su almacenamiento en GraphDB.

---

## ğŸ‘¥ Integrantes

- **Jean Villavicencio**
- **Samuel Reyes**
- **Sebastian Mendieta**

---

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline completo de ETL (Extract, Transform, Load) para construir un grafo de conocimiento sobre **Agricultura de PrecisiÃ³n** a partir de la API de Semantic Scholar. El proyecto se divide en tres fases:

1. **Fase 1**: ExtracciÃ³n, enriquecimiento y estructuraciÃ³n de datos acadÃ©micos
2. **Fase 2**: ConversiÃ³n de datos a formato RDF y almacenamiento en GraphDB
3. **Fase 3**: AnÃ¡lisis y explotaciÃ³n del grafo (futuro)

### Dominio: Agricultura de PrecisiÃ³n

La Agricultura de PrecisiÃ³n integra datos geoespaciales y temporales (mapas de rendimiento, humedad, Ã­ndices de vegetaciÃ³n, sensores en campo, imÃ¡genes de drones/satÃ©lites) y modelos de ML/IA para decidir con precisiÃ³n dÃ³nde, cuÃ¡nto y cuÃ¡ndo intervenir. El objetivo es producir mÃ¡s y mejor con menos insumos, reduciendo impacto ambiental y costos.

Este dominio es ideal para un grafo de conocimiento porque los papers conectan tecnologÃ­as (sensores, UAV, IoT), prÃ¡cticas (riego/fertilizaciÃ³n variable), cultivos, regiones y resultados medibles (rendimiento, eficiencia hÃ­drica, huella ambiental), generando relaciones ricas y consultables.

---

## ğŸ¯ Objetivos del Proyecto

### Fase 1: ExtracciÃ³n de Datos
- Extraer 1,000 publicaciones semilla sobre "precision agriculture" desde Semantic Scholar
- Enriquecer cada paper con metadatos completos (venue, citas, autores, referencias, campos de estudio)
- Construir un grafo de citaciones (relaciÃ³n CITES) sin self-edges ni duplicados
- Generar CSVs estructurados con nodos y relaciones
- Enriquecer top 200 autores con afiliaciones institucionales

### Fase 2: ConversiÃ³n RDF y GraphDB
- Convertir los datos extraÃ­dos y preprocesados a formato RDF segÃºn modelo comÃºn
- Utilizar vocabularios estÃ¡ndar (Schema.org, DCT, SKOS)
- Almacenar los datos en GraphDB
- Validar el modelo mediante consultas SPARQL

---

## ğŸ“¦ Entregables

### Fase 1
- âœ… Notebook Jupyter con cÃ³digo de extracciÃ³n y transformaciÃ³n
- âœ… 10 archivos CSV en `data/processed/` (nodos y relaciones)
- âœ… Esquema del modelo de datos (`data_model/schema.yml`)
- âœ… Notebook HTML exportado con resultados y visualizaciones

### Fase 2
- âœ… Datos RDF en formato Turtle (`notebooks/out/agri_graph.ttl`) y N-Triples (`agri_graph.nt`)
- âœ… Notebook HTML utilizado para convertir los datos a RDF
- âš ï¸ Datos RDF subidos en GraphDB (pendiente de ejecuciÃ³n)
- âš ï¸ Informe PDF que resuma las tres fases del proyecto con imÃ¡genes de GraphDB

---

## ğŸ—‚ï¸ Estructura del Proyecto

```
.
â”œâ”€â”€ data_model/
â”‚   â””â”€â”€ schema.yml                    # Esquema del grafo (nodos y relaciones)
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_extraccion_precision_agri.ipynb    # Notebook principal
â”‚   â”œâ”€â”€ 01_extraccion_precision_agri.html     # Notebook exportado a HTML
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ processed/                # CSVs finales (nodos y relaciones)
â”‚   â”‚   â”‚   â”œâ”€â”€ papers.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ authors.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ venues.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ fields.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_authoredby_author.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_publishedin_venue.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_has_topic.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ paper_cites_paper.csv
â”‚   â”‚   â”‚   â”œâ”€â”€ author_affiliations.csv
â”‚   â”‚   â”‚   â””â”€â”€ authors_enriched.csv
â”‚   â”‚   â””â”€â”€ raw/                      # Datos crudos (JSONs de la API)
â”‚   â””â”€â”€ out/                          # Archivos RDF generados
â”‚       â”œâ”€â”€ agri_graph.ttl            # RDF en formato Turtle
â”‚       â””â”€â”€ agri_graph.nt             # RDF en formato N-Triples
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                     # ConfiguraciÃ³n (API key, URLs)
â”‚   â”œâ”€â”€ semanticscholar_client.py    # Cliente HTTP para Semantic Scholar API
â”‚   â””â”€â”€ etl.py                        # Funciones de ETL (extracciÃ³n, transformaciÃ³n)
â”œâ”€â”€ .env                              # API key (NO commitear)
â”œâ”€â”€ requirements.txt                  # Dependencias Python
â”œâ”€â”€ README.md                         # Este archivo
â”œâ”€â”€ VERIFICACION_REQUISITOS.md        # Checklist Fase 1
â””â”€â”€ VERIFICACION_FASE2.md             # Checklist Fase 2
```

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### Prerrequisitos

- Python 3.10 o superior
- API Key de Semantic Scholar (gratis en https://www.semanticscholar.org/product/api)

### InstalaciÃ³n

```bash
# Clonar el repositorio
git clone <URL_DEL_REPO>
cd Bim1InteroperabilidadDatos-main

# Crear entorno virtual
python -m venv .venv

# Activar el entorno
# En Windows:
.venv\Scripts\activate
# En Linux/Mac:
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Instalar dependencias adicionales para RDF (si no estÃ¡n en requirements.txt)
pip install rdflib
```

### ConfiguraciÃ³n de API Key

Crea un archivo `.env` en la raÃ­z del proyecto:

```env
S2_API_KEY=tu_api_key_aqui
```

**âš ï¸ Importante**: No incluyas el archivo `.env` en el repositorio (estÃ¡ en `.gitignore`).

---

## ğŸ“– Uso del Proyecto

### Fase 1: ExtracciÃ³n de Datos

1. **Abrir el notebook**:
   ```bash
   jupyter notebook notebooks/01_extraccion_precision_agri.ipynb
   ```
   O desde VS Code: abre el archivo `.ipynb` directamente.

2. **Ejecutar el notebook completo**:
   - El notebook ejecuta automÃ¡ticamente:
     - BÃºsqueda de 1,000 papers con filtros especÃ­ficos
     - Descarga de detalles enriquecidos
     - ConstrucciÃ³n del grafo CITES
     - Enriquecimiento de afiliaciones de autores
     - GeneraciÃ³n de resÃºmenes y mÃ©tricas
     - ExportaciÃ³n de CSVs

3. **Tiempo estimado**: 20-30 minutos (depende de rate limits de la API)

4. **Exportar a HTML**:
   - Ejecuta la **celda 11** del notebook para exportaciÃ³n automÃ¡tica
   - O manualmente: `jupyter nbconvert --to html notebooks/01_extraccion_precision_agri.ipynb`

### Fase 2: ConversiÃ³n RDF y GraphDB

1. **Generar RDF**:
   - Ejecuta la **celda 12** del notebook
   - Esto genera `notebooks/out/agri_graph.ttl` y `agri_graph.nt`

2. **Cargar en GraphDB**:
   - Sigue las instrucciones detalladas en la **celda 13** del notebook:
     1. Crear repositorio `agri-precision` en GraphDB
     2. Configurar prefijos (ex, schema, dct, skos)
     3. Importar `agri_graph.ttl`
     4. Ejecutar consultas SPARQL de validaciÃ³n
     5. Tomar capturas de pantalla para el informe

---

## ğŸ” Filtros y ParÃ¡metros API Utilizados

### Endpoint: `/paper/search/bulk`

```python
{
    "query": "precision agriculture",
    "year": "2018-",
    "publicationTypes": "JournalArticle,Conference,Review,Proceedings,Survey",
    "sort": "publicationDate",
    "fields": "title,year,url,publicationTypes,publicationDate,citationCount",
    "token": "<pagination_token>"  # Para paginaciÃ³n
}
```

### Endpoint: `/paper/{paperId}`

```python
{
    "fields": "paperId,title,year,abstract,citationCount,influentialCitationCount,"
              "authors,externalIds,url,publicationTypes,venue,fieldsOfStudy,"
              "references.paperId"
}
```

### Endpoint: `/author/{authorId}`

```python
{
    "fields": "authorId,name,affiliations,url,paperCount,citationCount"
}
```

**Limitaciones respetadas:**
- Rate limit: 100 req/5min (free tier) â†’ se usa backoff exponencial
- MÃ¡x 1,000 papers por request en bulk search
- Campos anidados (`authors.affiliations`) no disponibles en Graph v1 â†’ enriquecimiento posterior

---

## ğŸ§© Modelo de Datos

El modelo de grafo se define en `data_model/schema.yml`:

### Nodos

- **Paper**: publicaciÃ³n cientÃ­fica (paperId, title, year, abstract, citationCount, doi, url, publicationTypes, venue)
- **Author**: autor (authorId, name, url)
- **Venue**: revista o conferencia (venueId, name)
- **Field**: campo de estudio (fieldName)

### Relaciones

- **AUTHORED_BY**: Paper â†’ Author (mapeado a `schema:author` en RDF)
- **PUBLISHED_IN**: Paper â†’ Venue (mapeado a `schema:isPartOf` en RDF)
- **HAS_TOPIC**: Paper â†’ Field (mapeado a `dct:subject` en RDF)
- **CITES**: Paper â†’ Paper (mapeado a `schema:citation` en RDF)

### Vocabularios RDF Utilizados

- **Schema.org**: Article, Person, Periodical, Organization, author, isPartOf, citation
- **Dublin Core Terms (DCT)**: subject
- **SKOS**: Concept, prefLabel

---

## ğŸ“Š Archivos Generados

### CSVs en `data/processed/`

| Archivo | DescripciÃ³n | Registros Aprox. |
|---------|-------------|------------------|
| `papers.csv` | Nodos de papers (1,000 semilla + stubs) | ~6,772 |
| `authors.csv` | Nodos de autores Ãºnicos | ~3,405 |
| `venues.csv` | Nodos de venues (revistas, conferencias) | ~446 |
| `fields.csv` | Nodos de campos de estudio | ~17 |
| `paper_authoredby_author.csv` | RelaciÃ³n Paper â†’ Author | ~3,826 |
| `paper_publishedin_venue.csv` | RelaciÃ³n Paper â†’ Venue | ~786 |
| `paper_has_topic.csv` | RelaciÃ³n Paper â†’ Field | ~1,349 |
| `paper_cites_paper.csv` | RelaciÃ³n CITES (Paper â†’ Paper) | ~6,328 |
| `author_affiliations.csv` | Afiliaciones de top 200 autores | Variable |
| `authors_enriched.csv` | Autores con paperCount y citationCount | 200 |

### Archivos RDF en `notebooks/out/`

- `agri_graph.ttl`: RDF en formato Turtle (~10-11 MB)
- `agri_graph.nt`: RDF en formato N-Triples (~10-11 MB)

---

## ğŸ“ˆ MÃ©tricas y ResÃºmenes

El notebook genera automÃ¡ticamente:

1. **DistribuciÃ³n temporal**: grÃ¡fica de publicaciones por aÃ±o
2. **Top 10 venues**: revistas/conferencias con mÃ¡s papers
3. **Top 10 autores**: autores mÃ¡s prolÃ­ficos
4. **Top 15 papers influyentes**: por `influentialCitationCount`
5. **MÃ©tricas del grafo CITES**:
   - Total de aristas: ~6,328
   - Papers que citan (sources): ~327 (2.4%)
   - Papers citados (targets): ~12,815 (93.2%)
   - Self-edges: 0
   - Duplicados: 0

---

## ğŸ”§ Consultas SPARQL para GraphDB

Una vez importado el RDF en GraphDB, puedes ejecutar estas consultas:

### A. ArtÃ­culos con autores, venue y conceptos

```sparql
PREFIX schema: <http://schema.org/>
PREFIX dct:    <http://purl.org/dc/terms/>
PREFIX skos:   <http://www.w3.org/2004/02/skos/core#>

SELECT ?art ?title ?author ?venue ?concept
WHERE {
  ?a a schema:Article ; schema:title ?title .
  OPTIONAL { ?a schema:author / schema:name ?author }
  OPTIONAL { ?a schema:isPartOf / schema:name ?venue }
  OPTIONAL { ?a dct:subject / skos:prefLabel ?concept }
  BIND(STR(?a) AS ?art)
}
LIMIT 25
```

### B. Top conceptos por cantidad de artÃ­culos

```sparql
PREFIX schema: <http://schema.org/>
PREFIX dct:    <http://purl.org/dc/terms/>
PREFIX skos:   <http://www.w3.org/2004/02/skos/core#>

SELECT ?concept ?label (COUNT(?a) AS ?n)
WHERE {
  ?a a schema:Article ; dct:subject ?c .
  ?c skos:prefLabel ?label .
  BIND(STR(?c) AS ?concept)
}
GROUP BY ?concept ?label
ORDER BY DESC(?n)
LIMIT 10
```

### C. Citas (paper â†’ paper)

```sparql
PREFIX schema: <http://schema.org/>

SELECT ?fromTitle ?toTitle
WHERE {
  ?from a schema:Article ; schema:citation ?to ;
        schema:title ?fromTitle .
  OPTIONAL { ?to schema:title ?toTitle }
}
LIMIT 25
```

---

## ğŸ“ Texto para el Informe PDF

### Fase 1: ExtracciÃ³n y Enriquecimiento

> **Cobertura y enriquecimiento.** Se recolectaron *1,000* publicaciones semilla desde *Semantic Scholar* (Graph API /paper/search/bulk) con la consulta "precision agriculture", filtros year=2018-, publicationTypes=JournalArticle,Conference,Review,Proceedings,Survey, y orden publicationDate. Para cada publicaciÃ³n se consultÃ³ /paper/{id} con fields especÃ­ficos: venue (string), publicationTypes, citationCount, influentialCitationCount, externalIds.DOI, url, authors y references.paperId.

> **Grafo de citaciÃ³n.** A partir de references.paperId se generÃ³ la relaciÃ³n *CITES* (paper â†’ paper citado), eliminando auto-citas y duplicados. Se incorporaron *nodos stub* para referencias externas no presentes en el conjunto base, con lo cual se preservan todas las conexiones.

> **Modelo de datos y reuso de vocabulario.** Nodos: Paper, Author, Venue, Field; relaciones: *AUTHORED_BY* (â‰ˆschema:author), *PUBLISHED_IN* (â‰ˆschema:isPartOf), *HAS_TOPIC* (â‰ˆschema:about), *CITES* (â‰ˆschema:citation).

> **ExploraciÃ³n y mÃ©tricas.** Se incluyen la distribuciÃ³n temporal, top venues, top autores y un ranking por influentialCitationCount; ademÃ¡s, mÃ©tricas de conectividad del grafo (porcentaje de papers que citan y que son citados).

> **Autores y afiliaciones.** Se enriquecieron los top 200 autores mÃ¡s prolÃ­ficos con llamadas al endpoint /author/{id}, obteniendo sus afiliaciones institucionales (cuando estÃ¡n disponibles), nÃºmero total de publicaciones y conteo de citas.

> **Apuntes de implementaciÃ³n.** Se manejaron lÃ­mites de tasa con backoff y *reintentos selectivos* (de 998â†’*1000/1000*). El campo venue se maneja como string por restricciones de campos en Graph v1; se reporta el url del paper como enlace principal.

### Fase 2: ConversiÃ³n RDF y GraphDB

> **Modelo RDF y vocabularios estÃ¡ndar.** Los datos extraÃ­dos y preprocesados (CSVs en `data/processed/`) se convirtieron a formato RDF usando vocabularios estÃ¡ndar: Schema.org para entidades principales (Article, Person, Periodical, Organization), Dublin Core Terms (DCT) para subjects, y SKOS para conceptos. El modelo RDF preserva la estructura del grafo definida en `data_model/schema.yml`, mapeando Papers a `schema:Article`, Authors a `schema:Person`, Venues a `schema:Periodical`, y Fields a `skos:Concept`. Las relaciones se representan mediante propiedades estÃ¡ndar: `schema:author` (AUTHORED_BY), `schema:isPartOf` (PUBLISHED_IN), `dct:subject` (HAS_TOPIC), y `schema:citation` (CITES).

> **GeneraciÃ³n de triples.** Se generaron dos formatos de salida: Turtle (TTL) y N-Triples (NT), con un total de aproximadamente [N] triples RDF. El archivo principal `agri_graph.ttl` tiene un tamaÃ±o de ~10-11 MB y contiene todas las entidades y relaciones del grafo de conocimiento.

> **Almacenamiento en GraphDB.** Se creÃ³ el repositorio `agri-precision` en GraphDB con configuraciÃ³n estÃ¡ndar (RDF4J, OWL-Horst). Se configuraron los namespaces necesarios: `ex` (http://example.org/agri#), `schema` (http://schema.org/), `dct` (http://purl.org/dc/terms/), y `skos` (http://www.w3.org/2004/02/skos/core#). El archivo RDF se importÃ³ exitosamente, preservando la integridad de todos los triples.

> **ExploraciÃ³n y consultas SPARQL.** Se realizaron consultas SPARQL para validar el modelo y explorar el grafo: (1) artÃ­culos con sus autores, venues y conceptos asociados; (2) top conceptos por cantidad de artÃ­culos; (3) relaciones de citaciÃ³n entre papers. El visualizador de grafo de GraphDB permite explorar las conexiones entre Article, Person, Periodical y Concept, confirmando la estructura del modelo de conocimiento.

---

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: "API Key cargada: âŒ No"

1. Verifica que `.env` existe en la raÃ­z del proyecto
2. El contenido debe ser: `S2_API_KEY=tu_key_aqui` (sin espacios extras)
3. Reinicia el kernel del notebook

### Error: "Rate limit exceeded (429)"

- El cÃ³digo ya maneja esto con backoff automÃ¡tico
- Si persiste, aumenta el delay en `time.sleep()` en las celdas de retry

### Error: "Solo hay X candidatos; aumenta el target"

- Relaja los filtros en la celda 2:
  - Cambia `YEAR = "2018-"` a `"2010-"` o anterior
  - AÃ±ade mÃ¡s tipos en `PUB_TYPES`

### No se obtienen afiliaciones

- Semantic Scholar no siempre expone afiliaciones en Graph API v1
- Es normal que algunos autores no tengan este campo
- El cÃ³digo genera `author_affiliations.csv` solo con los disponibles

### Error al generar RDF

- Verifica que todos los CSVs existen en `data/processed/`
- Ejecuta primero todas las celdas de la Fase 1
- Revisa que `rdflib` estÃ© instalado: `pip install rdflib`

---

## ğŸ“¸ Capturas Necesarias para el Informe

Para el informe PDF final, necesitas tomar estas capturas de GraphDB:

1. **Repositorio creado** (`agri-precision`) en GraphDB
2. **Import success** (pantalla que muestra el conteo de triples despuÃ©s de importar)
3. **Visual Graph** con nodos Articleâ€“Personâ€“Periodicalâ€“Concept (1-2 capturas)
4. **Resultados de consulta SPARQL A** (artÃ­culos con autores, venues, conceptos)
5. **Resultados de consulta SPARQL B** (top conceptos por cantidad)
6. **Resultados de consulta SPARQL C** (citas paper â†’ paper)

---

## âœ… Checklist de Entregables

### Fase 1
- [x] Notebook con cÃ³digo de extracciÃ³n (`01_extraccion_precision_agri.ipynb`)
- [x] 10 CSVs en `data/processed/`
- [x] Esquema del modelo (`data_model/schema.yml`)
- [x] Notebook HTML exportado (`01_extraccion_precision_agri.html`)

### Fase 2
- [x] CÃ³digo de conversiÃ³n RDF (celda 12 del notebook)
- [x] Archivos RDF generados (`agri_graph.ttl` y `agri_graph.nt`)
- [x] Instrucciones GraphDB (celda 13 del notebook)
- [ ] RDF importado en GraphDB (pendiente de ejecuciÃ³n)
- [ ] Capturas de GraphDB tomadas (pendiente)
- [ ] Informe PDF final creado (pendiente)

---

## ğŸ”— Referencias

- **Semantic Scholar API Docs**: https://api.semanticscholar.org/api-docs/graph
- **Schema.org Vocabulary**: https://schema.org/
- **Dublin Core Terms**: http://purl.org/dc/terms/
- **SKOS**: https://www.w3.org/2004/02/skos/core
- **GraphDB Documentation**: https://graphdb.ontotext.com/documentation/

---

## ğŸ“„ Licencia

Este proyecto es parte de un trabajo acadÃ©mico para la UTPL - Interoperabilidad y ExplotaciÃ³n de Datos en Ecosistemas HeterogÃ©neos (BIM1).

---

## ğŸ“š DocumentaciÃ³n Adicional

- `VERIFICACION_REQUISITOS.md`: Checklist completo de la Fase 1
- `VERIFICACION_FASE2.md`: Checklist completo de la Fase 2
- `data_model/schema.yml`: Esquema del modelo de datos

---

**Ãšltima actualizaciÃ³n**: Diciembre 2024
